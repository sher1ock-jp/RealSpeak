# RealSpeak - プロダクト設計書

## 1. 製品概要

RealSpeakは、実際の英会話環境をより忠実に再現し、ユーザーの興味に合わせたコンテキストで英会話学習を提供するWebサービスです。従来の英会話学習サービスの課題を解決し、より自然で実践的な英語学習体験を提供します。

## 2. 課題と解決策

### 2.1 課題

1. **非現実的な会話環境**：
   - 現在の英会話サービスは実際の英会話環境を十分に再現できていない
   - 実際の会話では複数の人がオーバラップ的に話し、様々なイントネーションも存在する

2. **興味の欠如**：
   - 提供されるテーマがユーザーの興味や実際の状況に合わず、会話に没入できない
   - 没入感の欠如により学習効果が低下

### 2.2 解決策

1. **コンテキスト認識型会話生成**：
   - ユーザーの現在位置情報や画像アップロードから状況や環境を把握
   - 「この状況でどんな会話が発生するだろう？」という疑問に応える多様な会話パターンを生成

2. **リアルな多人数会話シミュレーション**：
   - 複数人による自然な会話を再現（割り込み、同時発話など）
   - 1,3,5分間の任意の時間の会話セッションを生成し、実践的な会話を提供

3. **パーソナライズされたテーマ選定**：
   - ユーザーがリクエストしたテーマについて、MCPなどを活用して専門的・具体的な情報を抽出し、知的好奇心も満たす会話生成
   - ユーザーの過去の会話履歴を参考にした会話生成

## 3. 主要機能

### 3.1 コンテキスト取得機能

- **画像アップロード分析**：
  - ユーザーがアップロードした画像からLLMが状況を分析
  - 「この状況でどんな会話が発生するか」を推測し、多様な会話パターンを提案

- **位置情報活用**：
  - GPSデータを利用してユーザーの現在地を特定
  - 周辺環境に合わせた会話コンテキストの提案

### 3.2 会話生成エンジン

- **LLMによる多人数会話生成**：
  - 2〜4人の自然な会話を生成
  - 会話の重なり、割り込み、相槌などを再現
  - ユーザーの過去の会話履歴を参考にした自然な会話の流れを生成
  
- **カスタマイズされた英会話**
  - イントネーションやスピードを調整して、より自然な会話を生成
  - アクセントを選択して、より自然な会話を生成

- **音声合成**：
  - OpenAIのTTSを活用した高品質な音声生成
  - 話者ごとに異なる声色、イントネーション、スピードを設定

### 3.3 パーソナライゼーション

- **テーマ情報抽出**：
  - ユーザーがリクエストしたテーマについてMCPを活用して専門的・具体的な情報を抽出
  - 抽出した情報を基に、より深みのある会話を生成

- **会話履歴活用**：
  - 過去の会話で出てきたトピックや表現を新しい会話に自然に組み込む
  - ユーザーの学習進度に合わせた表現の再利用

### 3.4 学習支援機能

- **トランスクリプト表示**：
  - 会話の文字起こしをリアルタイム表示
  - 重要表現のハイライト

- **単語・フレーズ学習**：
  - 会話内の重要表現を抽出して復習可能
  - フラッシュカード形式での学習機能

## 4. 技術仕様

### 4.1 バックエンド

- **言語/フレームワーク**：
  - Python
  - FastAPI

- **画像認識**：
  - OpenAI gpt-4.1

- **会話生成**：
  - OpenAI gpt-4.1
  - LiteLLM（複数のLLMプロバイダーを統一インターフェースで利用）

- **音声合成**：
  - OpenAI TTS
  - Web Audio API（音声オーバーラップ処理）

- **データベース**：
  - Supabase（PostgreSQL）
  - ベクトルデータベース（pgvector）

### 4.2 フロントエンド

- **Web**：
  - TypeScript
  - Next.js
  - Tailwind CSS
  - Shadcn/UI
  - 状態管理：React Query + Zustand/Jotai
  - Responsive design（スマホ対応）

- **モバイル対応**：
  - PWA（Progressive Web App）
  - next-pwa

### 4.3 インフラストラクチャ

- **クラウドサービス**：
  - Vercel（デプロイ、サーバーレス関数）
  - Supabase（バックエンドサービス）

- **認証**：
  - Supabase Auth

- **モニタリング**：
  - Sentry（エラー追跡）
  - Vercel Analytics（利用状況分析）

- **CI/CD**：
  - GitHub Actions + Vercel

### 4.4 データ処理アーキテクチャ

- **ベクトルデータベースの活用**：
  - ユーザーの会話履歴をベクトル化して保存し、意味ベースの検索を実現
  - ユーザーの好みや関心をベクトルとして保存し、パーソナライゼーションに活用
  - 画像から抽出したコンテキスト情報とユーザー履歴を関連付け

- **データモデル例**：
  ```
  -- 会話履歴テーブル
  CREATE TABLE conversation_history (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    conversation_text TEXT,
    embedding VECTOR(1536),  -- OpenAIのエンベディングサイズ
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE
  );
  
  -- ユーザー好みテーブル
  CREATE TABLE user_preferences (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    preference_type TEXT,
    preference_value TEXT,
    embedding VECTOR(1536),
    created_at TIMESTAMP WITH TIME ZONE
  );
  ```

## 5. システム設計詳細

### 5.1 インプット（入力）

1. **ユーザーのコンテキスト情報**:
   - 画像アップロード（ユーザーが撮影した状況/環境の画像）
   - 位置情報（GPSデータ）
   
2. **ユーザーの好み**:
   - リクエストしたテーマ
   - 会話時間の長さ（1分、3分、5分など）
   - アクセントの選択
   
3. **過去の学習データ**:
   - 会話履歴
   - 学習進度

### 5.2 パラメーター

1. **会話生成パラメーター**:
   - 会話の長さ（1分、3分、5分）
   - 話者の数（2〜4人）
   - 会話のテーマ/状況
   
2. **音声合成パラメーター**:
   - 話者ごとの声色
   - イントネーション
   - 話すスピード
   - アクセントの種類
   
3. **学習パラメーター**:
   - 難易度レベル
   - 重要表現のハイライト基準

### 5.3 アウトプット（出力）

1. **生成コンテンツ**:
   - 多人数による自然な英会話音声（オーバーラップ、割り込みなどを含む）
   - 会話のトランスクリプト（文字起こし）
   - 重要表現のハイライト
   
2. **学習支援コンテンツ**:
   - 重要単語・フレーズの抽出
   - フラッシュカード形式の学習素材

### 5.4 必要なデータテーブル

1. **ユーザーテーブル**:
   - ユーザーID、プロフィール情報、設定など
   
2. **会話履歴テーブル**:
   - 生成された会話の履歴、メタデータ
   - ユーザーの反応や評価
   
3. **学習進度テーブル**:
   - 学習した表現、単語
   - 復習状況、習熟度
   
4. **コンテキストデータテーブル**:
   - アップロードされた画像とその分析結果
   - 位置情報の履歴と関連コンテキスト
   
5. **テーマ情報テーブル**:
   - MCPから抽出した専門的・具体的な情報
   - よく使われるテーマとその関連情報

## 6. 実装計画

### 6.1 スプリント実装順序

1. **スプリント1: 基本会話生成機能**
   - LLMによる基本的な会話生成（重なりなし）
   - 基本的な音声合成
   - シンプルなWebインターフェース

2. **スプリント2: コンテキスト取得機能**
   - 画像アップロード・分析機能
   - 位置情報活用機能
   - コンテキストに基づく会話生成

3. **スプリント3: リアルな会話表現**
   - 複数人の会話オーバーラップ機能
   - 割り込み、相槌などの自然な会話要素
   - 音声合成の品質向上

4. **スプリント4: パーソナライゼーション**
   - テーマ情報抽出（MCP活用）
   - 会話履歴の活用
   - ユーザー好みに合わせた会話生成

5. **スプリント5: 学習支援機能**
   - トランスクリプト表示
   - 重要表現のハイライト
   - 単語・フレーズ学習機能

6. **スプリント6: モバイル対応とUX改善**
   - PWA対応
   - レスポンシブデザイン最適化
   - ユーザーフィードバックに基づく改善

7. **スプリント7: スケーラビリティとパフォーマンス**
   - インフラストラクチャの最適化
   - キャッシング戦略
   - 負荷テストと改善

## 7. プロジェクトディレクトリ構造

プロジェクトは以下のディレクトリ構造で開発を進めます。モノレポ構造を採用し、フロントエンドとバックエンドを一つのリポジトリで管理します。

```
/RealSpeak
│
├── /apps                      # モノレポ構造（複数アプリケーション管理）
│   ├── /web                   # フロントエンドアプリケーション（Next.js）
│   │   ├── /app               # App Router
│   │   │   ├── /api           # API Routes
│   │   │   ├── /(auth)        # 認証関連ページ
│   │   │   ├── /dashboard     # ダッシュボード
│   │   │   ├── /conversations # 会話生成・表示
│   │   │   └── /settings      # ユーザー設定
│   │   ├── /components        # 共通コンポーネント
│   │   │   ├── /ui            # UIコンポーネント
│   │   │   ├── /conversation  # 会話関連コンポーネント
│   │   │   └── /audio         # 音声再生コンポーネント
│   │   ├── /lib               # ユーティリティ関数
│   │   │   ├── /supabase      # Supabaseクライアント
│   │   │   └── /audio         # 音声処理ユーティリティ
│   │   ├── /hooks             # カスタムReactフック
│   │   ├── /styles            # グローバルスタイル
│   │   ├── /public            # 静的ファイル
│   │   ├── next.config.js     # Next.js設定
│   │   ├── package.json
│   │   └── tsconfig.json
│   │
│   └── /api                   # バックエンドAPI（Python/FastAPI）
│       ├── /src
│       │   ├── /api           # APIエンドポイント
│       │   │   ├── /v1        # APIバージョン
│       │   │   └── router.py  # APIルーター
│       │   ├── /core          # コアロジック
│       │   │   ├── /config    # 設定
│       │   │   ├── /security  # 認証・認可
│       │   │   └── /errors    # エラーハンドリング
│       │   ├── /services      # ビジネスロジック
│       │   │   ├── /llm       # LLM関連サービス
│       │   │   ├── /audio     # 音声合成サービス
│       │   │   ├── /context   # コンテキスト分析
│       │   │   └── /user      # ユーザー関連サービス
│       │   ├── /db            # データベース
│       │   │   ├── /models    # データモデル
│       │   │   ├── /crud      # CRUD操作
│       │   │   └── /migrations # マイグレーション
│       │   ├── /utils         # ユーティリティ
│       │   └── main.py        # アプリケーションエントリーポイント
│       ├── /tests             # テスト
│       ├── requirements.txt   # 依存関係
│       └── Dockerfile         # Dockerファイル
│
├── /packages                  # 共有パッケージ
│   ├── /eslint-config         # ESLint設定
│   ├── /typescript-config     # TypeScript設定
│   ├── /ui                    # 共有UIコンポーネント
│   └── /utils                 # 共有ユーティリティ
│
├── /docs                      # ドキュメント
│   ├── product_design.md      # 製品設計書
│   ├── technical_architecture.md # 技術アーキテクチャ
│   └── api_docs.md            # API仕様書
│
├── /scripts                   # ユーティリティスクリプト
│   ├── setup.sh               # セットアップスクリプト
│   └── deploy.sh              # デプロイスクリプト
│
├── /infra                     # インフラストラクチャコード
│   ├── /vercel                # Vercel設定
│   └── /supabase              # Supabase設定・マイグレーション
│
├── .github                    # GitHub Actions
│   └── /workflows             # CI/CDワークフロー
│
├── .gitignore
├── package.json               # ルートパッケージ
├── turbo.json                 # Turborepo設定
└── README.md
```

### 7.1 ディレクトリ構造の特徴

- **モノレポ構造**: Turborepoを使用して、フロントエンドとバックエンドを一つのリポジトリで管理
- **機能ベースの分割**: 関連するコードを機能ごとにグループ化
- **スケーラビリティ**: 将来の拡張に対応できる構造
- **モジュール性**: 明確な責任分担と依存関係の管理
